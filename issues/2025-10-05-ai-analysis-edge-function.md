# AI Analysis Edge Function for Cloud Trader Execution

## Metadata
- **Status:** üîç engineering-review
- **Created:** 2025-10-05T17:30:00Z
- **Updated:** 2025-10-05T18:00:00Z
- **Priority:** High
- **Type:** feature
- **Progress:** [‚ñà‚ñà        ] 20%

---

## Idea Review
*Stage: idea | Date: 2025-10-05T17:30:00Z*

### Original Idea
Port the browser's `browserAnalysisEngine.ts` logic to a Deno-based Supabase Edge Function to enable cloud-based AI analysis of trading signals. The Edge Function should:

1. Receive signal data (symbol, strategy, market data)
2. Call Gemini API via Firebase AI Logic (or direct Gemini API)
3. Return structured analysis
4. Handle errors/retries

**Current State:**
- Edge Function stub exists at `supabase/functions/ai-analysis/` (only `deno.json`)
- Browser implementation working: `browserAnalysisEngine.ts` + `geminiService.ts`
- `ConcurrentAnalyzer` on Fly machine ready to call this Edge Function
- Rate limiting designed: 60 req/min, max 4 concurrent per user

### Enhanced Concept
**Serverless AI Analysis Pipeline for 24/7 Trading Signal Intelligence**

Transform the cloud trading infrastructure from simple signal detection to intelligent, AI-powered trade analysis that runs independently of the browser. This enables Elite traders to get sophisticated market analysis for every signal generated by their Fly machines, even when they're asleep.

**Architecture Evolution:**

**Current (Browser-Only):**
```
Browser ‚Üí Detect Signal ‚Üí Call Gemini via Firebase AI Logic ‚Üí Display Analysis
```

**Target (Hybrid Cloud):**
```
Fly Machine ‚Üí Detect Signal ‚Üí Queue for Analysis
                ‚Üì
            Edge Function ‚Üí Call Gemini API ‚Üí Return Structured Analysis
                ‚Üì
            Store in Database ‚Üí Notify User ‚Üí Display in Browser
```

**Key Innovation:**
- **Separation of Concerns**: Signal detection (fast, high-volume) runs on Fly, AI analysis (slow, rate-limited) runs serverless
- **Queue-Based Architecture**: ConcurrentAnalyzer manages rate limits and retries, Edge Function focuses on AI logic
- **Cost Optimization**: Edge Functions auto-scale and only run when needed (vs. always-on Fly machine doing AI calls)
- **Reliability**: Retry logic, timeout handling, and error recovery built into both layers

### Target Users

- **Primary:** Elite tier algorithmic traders who run 24/7 cloud execution
  - Need AI analysis for every signal without browser open
  - Expect sub-5-second analysis latency
  - Require 99.9% uptime for analysis pipeline
  - Value professional-grade error handling and observability

- **Secondary:** Pro users who may upgrade to cloud execution
  - Want to test cloud AI analysis before committing to Elite tier
  - Need confidence that cloud analysis matches browser quality
  - Appreciate transparent cost/performance tradeoffs

- **Edge Case:** High-frequency traders monitoring 100+ symbols
  - Generate 50-100 signals per hour during volatile markets
  - Need queue management to handle bursts without hitting rate limits
  - Require priority analysis for high-confidence signals

### Domain Context

**Cryptocurrency Algorithmic Trading:**

**Market Reality:**
- Crypto markets trade 24/7 with high volatility
- Opportunities appear and disappear in minutes
- AI analysis must be fast (<5s) to remain actionable
- Missing a signal's optimal entry costs real money

**Why Serverless Edge Functions:**
- **Cost**: Only pay for analysis when signals trigger (vs. idle AI capacity)
- **Scale**: Auto-scale during high-volatility periods (Bitcoin flash crashes, altcoin pumps)
- **Latency**: Deployed globally on Cloudflare/Deno Deploy (sub-100ms to Gemini API)
- **Reliability**: Managed infrastructure with automatic failover

**Competitive Landscape:**
- **TradingView**: Cloud-based alerts but NO AI analysis (just technical triggers)
- **3Commas**: AI signals but proprietary black-box (users can't customize)
- **Coinrule**: Template-based strategies, no adaptive AI analysis
- **Our Advantage**: User-defined strategies + Gemini-powered adaptive analysis in the cloud

**Why Users Need This NOW:**
1. **Fly machines are live** but only generating raw signals (incomplete value prop)
2. **Elite tier launch pending** - this is the differentiating feature
3. **AI costs dropping** - Gemini 2.5 Flash is 10x cheaper than GPT-4, making this economical
4. **Competition heating up** - every delay lets competitors catch up

### Suggestions for Improvement

1. **Dual-Path Gemini Integration:**
   - **Path A (Recommended)**: Direct Gemini API calls from Edge Function
     - Pro: Simpler, faster (no Firebase overhead), better error messages
     - Pro: Uses Deno's native `fetch`, no dependency on Firebase client libs
     - Con: Need to manage API keys in Supabase secrets
   - **Path B**: Firebase AI Logic (reuse browser setup)
     - Pro: Consistent with browser implementation
     - Con: Firebase client may not work well in Deno/Edge Function environment
     - Con: Additional latency from Firebase proxy layer
   - **Why it matters**: Direct API is cleaner for serverless, Firebase adds unnecessary complexity

2. **Streaming Response Support:**
   - Gemini supports streaming - Edge Function should too
   - Benefits: Faster perceived latency, progressive updates to UI
   - Implementation: Use Server-Sent Events (SSE) from Edge Function
   - **Why it matters**: In trading, every second counts. Streaming shows "AI is working" immediately

3. **Analysis Result Caching:**
   - Cache analysis for same symbol+strategy within 5-minute window
   - Reduces Gemini API costs by ~30% during high-signal periods
   - Store in Supabase with TTL or in-memory on Edge Function (less reliable)
   - **Why it matters**: Same setup appearing twice in 5 minutes likely has same analysis

4. **Fallback to Browser Analysis:**
   - If Edge Function fails/times out, browser can still analyze locally
   - Graceful degradation maintains user experience
   - Track Edge Function vs. Browser analysis ratio for monitoring
   - **Why it matters**: Users should never see "Analysis unavailable" - always have a backup

5. **Comprehensive Observability:**
   - Log every Edge Function invocation with correlation IDs
   - Track: Analysis latency, Gemini token usage, error rates, queue depth
   - Alert on: >10% error rate, >10s P99 latency, Gemini quota exhaustion
   - **Why it matters**: Trading systems require ops visibility - can't debug in production without logs

### Critical Questions

#### API Integration Strategy
1. **Should we use Firebase AI Logic or direct Gemini API calls from the Edge Function?**
   - **Why it matters**: Firebase AI Logic works great in browser but may have compatibility/latency issues in Deno. Direct API is simpler but requires managing API keys differently.
   - **Recommendation**: Start with direct Gemini API (Path A). Firebase's value is browser API key security, which doesn't apply to Edge Functions (they're server-side). Use Supabase secrets for the Gemini API key.
   - **Trade-off**: Lose consistency with browser code, gain simplicity and performance.

2. **How do we handle Gemini API key rotation without redeploying?**
   - **Why it matters**: API keys expire, get compromised, or hit quota limits. Need hot-swap capability.
   - **Recommendation**: Store in Supabase secrets (accessible via environment variables). Update with `supabase secrets set GEMINI_API_KEY=xxx` - no redeploy needed.
   - **Trade-off**: Adds dependency on Supabase secrets management.

#### Rate Limiting & Queueing
3. **Is 60 req/min and 4 concurrent enough for Elite users during high-volatility events?**
   - **Why it matters**: During Bitcoin flash crashes, 100+ symbols might trigger signals simultaneously. If queue backs up >5 minutes, analysis becomes stale/useless.
   - **Recommendation**: Implement priority queue - high-confidence signals jump the line. Add burst capacity (allow 10 concurrent for 60 seconds if queue depth >20).
   - **Trade-off**: Risk hitting Gemini's hard rate limits (429 errors), but better than stale analysis.

4. **Should ConcurrentAnalyzer or Edge Function enforce rate limits?**
   - **Why it matters**: Double rate limiting wastes resources. Single point is simpler but creates a dependency.
   - **Recommendation**: ConcurrentAnalyzer handles queueing/scheduling (it has full context of all pending analyses). Edge Function just executes and returns errors if Gemini rate limits hit.
   - **Trade-off**: Edge Function becomes "dumb executor" - can't independently throttle if ConcurrentAnalyzer misbehaves.

#### Data & Schema
5. **What data format should the Edge Function receive and return?**
   - **Why it matters**: Mismatch between Fly machine's signal format and Edge Function's expected input will cause runtime errors.
   - **Recommendation**: Define strict TypeScript interfaces (share types between Fly and Edge Function). Input: `{ signalId, traderId, symbol, price, klines, strategy, indicators }`. Output: `{ analysisResult, confidence, keyLevels, tradePlan }`.
   - **Trade-off**: More upfront work defining schemas, but prevents production bugs.

6. **Should we store raw Gemini responses in the database for debugging/retraining?**
   - **Why it matters**: Gemini responses can be unpredictable. If analysis quality degrades, need historical data to investigate.
   - **Recommendation**: Yes - add `raw_ai_response` JSONB column to `signal_analyses` table. Set retention policy (delete after 30 days to save storage).
   - **Trade-off**: Increases database storage costs by ~10%, but invaluable for debugging/improving prompts.

#### Error Handling & Reliability
7. **What happens if Gemini returns invalid JSON or times out?**
   - **Why it matters**: Gemini sometimes returns malformed JSON or doesn't respond. Can't let one bad response crash the entire analysis pipeline.
   - **Recommendation**: 3-tier fallback: (1) Retry once with same prompt (transient errors), (2) Return conservative "bad_setup" analysis (permanent errors), (3) Log error with full context for investigation.
   - **Trade-off**: Users might see "bad_setup" for legitimate signals during Gemini outages, but better than no analysis.

8. **Should failed analyses retry immediately or wait for next signal?**
   - **Why it matters**: If Gemini is down for 10 minutes, retrying immediately will exhaust queue and waste resources.
   - **Recommendation**: Exponential backoff with jitter (1s, 2s, 4s delays). After 3 attempts, mark as "analysis_failed" and notify user. Don't block queue on failures.
   - **Trade-off**: Increased complexity in retry logic, but prevents cascading failures.

#### Cost & Performance
9. **What's the expected Gemini API cost per Elite user per month?**
   - **Why it matters**: Need to ensure Elite tier pricing ($99/month) covers infrastructure costs with healthy margin.
   - **Recommendation**: Estimate: 1000 signals/month √ó $0.0001/analysis (Gemini 2.5 Flash) = $0.10/month. Even 10,000 signals = $1/month. Cost is negligible - focus on quality.
   - **Trade-off**: None - this is incredibly cheap compared to value provided.

10. **Should we implement analysis result streaming or wait for complete response?**
    - **Why it matters**: Gemini supports streaming tokens. Streaming shows progress, but adds complexity.
    - **Recommendation**: V1 = wait for complete response (simpler). V2 = add streaming if users complain about "black box" delay.
    - **Trade-off**: Worse perceived latency in V1, but faster to ship.

### Success Criteria
- [ ] Edge Function analyzes 95% of signals within 5 seconds (P95 latency)
- [ ] Zero analysis failures due to Gemini rate limits (queue should absorb bursts)
- [ ] Analysis quality matches browser implementation (same prompts, same results)
- [ ] Gemini API costs <$2/month per Elite user at 1000 signals/month
- [ ] 99% uptime for Edge Function (excluding Gemini API outages)
- [ ] Full observability: Every analysis logged with latency, tokens used, errors
- [ ] Graceful degradation: If Edge Function down, browser can still analyze

### Risks & Mitigations
| Risk | Impact | Mitigation |
|------|--------|------------|
| **Gemini API quota exhaustion during flash crashes** | High | Priority queue for high-confidence signals; alert at 80% quota; fallback to browser analysis |
| **Edge Function cold starts (5-10s latency)** | Medium | Keep function warm with scheduled health checks every 5 minutes |
| **Deno environment differences from Node.js (screenerHelpers may not work)** | High | Copy screenerHelpers to Edge Function, test thoroughly; consider Deno-native rewrites if needed |
| **Firebase AI Logic incompatible with Deno** | Critical | Use direct Gemini API instead (recommended Path A) |
| **Analysis quality worse than browser (different prompts/context)** | High | Use identical prompts; extensive testing with historical signals; gradual rollout |
| **ConcurrentAnalyzer and Edge Function rate limits misaligned** | Medium | Single source of truth for rate limits (ConcurrentAnalyzer); Edge Function returns 429 ‚Üí ConcurrentAnalyzer backs off |
| **Database schema mismatch (signal data vs. Edge Function expectations)** | Critical | Define strict TypeScript interfaces; integration tests with real database; schema validation on both ends |

### Recommended Next Steps
1. **Choose API integration path** (Firebase AI Logic vs. direct Gemini API)
   - Recommendation: Direct Gemini API for simplicity
2. **Define Edge Function input/output schemas** (TypeScript interfaces)
3. **Copy/adapt screenerHelpers.ts to Deno environment** (technical indicators)
4. **Create detailed spec with /spec** including:
   - Request/response formats
   - Error handling strategy
   - Rate limiting coordination with ConcurrentAnalyzer
   - Database schema updates (signal_analyses table)
   - Observability requirements
5. **Build MVP**: Basic Edge Function that accepts signal, calls Gemini, returns analysis
6. **Integration testing**: Fly machine ‚Üí Edge Function ‚Üí Database round-trip
7. **Gradual rollout**: Elite users opt-in, monitor for 1 week, then auto-enable

### Priority Assessment
**Urgency:** High
**Impact:** High (blocks Elite tier launch, differentiates product)
**Effort:** M (3-5 days for experienced developer with Deno/Edge Functions experience)
**Recommendation:** **Proceed immediately** - this is the last missing piece for cloud trader execution. Fly machines are generating signals but without AI analysis, the value proposition is incomplete.

**Why High Priority:**
- Elite tier feature set incomplete without this
- Competitors are shipping AI analysis features
- Gemini 2.5 Flash pricing makes this economically viable now (wasn't 6 months ago)
- Existing browser implementation de-risks this (proven AI logic, just needs porting)

**De-Risking Strategy:**
- Start with direct Gemini API (avoid Firebase compatibility unknowns)
- Reuse browser prompts exactly (proven to work)
- Extensive testing with historical signals before production
- Gradual rollout to Elite users with browser fallback

---
*[End of idea review. Next: /spec issues/2025-10-05-ai-analysis-edge-function.md]*

---

## Engineering Review
*Stage: engineering-review | Date: 2025-10-05T18:00:00Z*

### Codebase Analysis

#### Relevant Existing Code
**Components to reuse:**
- `browserAnalysisEngine.ts` (293 lines): Complete AI analysis implementation with key level calculation, ATR-based stops, response parsing
- `geminiService.ts:generateStructuredAnalysis()` (lines 583-690): Proven Gemini API integration with Firebase AI Logic, prompt management, rate limiting
- `ConcurrentAnalyzer.ts` (296 lines): Queue management, priority sorting, retry logic with exponential backoff - **ready to call Edge Function, just needs implementation**
- `screenerHelpers.ts` (1,420 lines): 40+ technical indicator functions already on Fly machine - **reused as-is, no porting needed**
- `promptManager.ts`: Centralized prompt template system with variables - Edge Function should use same prompts for consistency

**Patterns to follow:**
- Firebase AI Logic integration pattern from `geminiService.ts` - uses `getGenerativeModel()` with JSON response mode
- Error handling: 3-tier fallback (retry ‚Üí safe default ‚Üí log error) from `browserAnalysisEngine.ts:166-195`
- Observability: `observability.trackAnalysis()` pattern with latency, token usage, correlation IDs
- Rate limiting: `aiRateLimiter.execute()` wrapper pattern for queuing Gemini calls
- Schema validation: All Gemini responses parsed with JSON.parse() and validated before use

**Technical debt to address:**
- ‚ö†Ô∏è **Firebase AI Logic in Deno**: `firebase/ai` npm package designed for browser/Node.js - likely incompatible with Deno runtime
- ‚ö†Ô∏è **No shared type definitions**: Fly machine, Edge Function, browser use different type files - need unified interface for signal data
- ‚ö†Ô∏è **Missing signal_analyses table**: Database has `signals` table and `monitoring_decisions` table but no dedicated `signal_analyses` table for storing Edge Function results

**Performance baseline:**
- Browser Gemini calls (via Firebase AI Logic): **2-4s P50**, **5-8s P95** (including prompt construction + API round-trip)
- ConcurrentAnalyzer queue processing loop: **100ms polling interval** (reasonable for 30s timeout budget)
- Supabase Edge Functions cold start: **~500-2000ms** (Deno Deploy infrastructure)
- Gemini 2.5 Flash API direct: **1-3s typical**, **up to 10s during quota throttling**
- **Target**: Must match or beat browser performance (<5s P95) to justify cloud execution

### Spec Analysis

#### Technical Feasibility
**Verdict:** ‚ö†Ô∏è **Challenging but achievable** - Core logic is proven, but environment adaptation has hidden complexity

**Reasoning:**

**What Makes This Feasible:**
1. ‚úÖ **Proven AI logic**: Browser implementation works reliably (running in production for months)
2. ‚úÖ **Queue infrastructure ready**: ConcurrentAnalyzer fully implemented and tested on Fly
3. ‚úÖ **Direct Gemini API simpler**: Avoid Firebase/Deno compatibility issues by using direct REST API
4. ‚úÖ **Deno-friendly architecture**: Supabase Edge Functions are designed for this exact use case (serverless AI)
5. ‚úÖ **Cost is negligible**: $0.10-$1/month per user makes experimentation risk-free

**What Makes This Challenging:**
1. ‚ö†Ô∏è **Firebase AI Logic incompatibility**: Browser uses `firebase/ai` which won't work in Deno - need to rewrite Gemini integration from scratch using direct REST API
2. ‚ö†Ô∏è **No shared types**: Signal format between Fly and Edge Function undocumented - schema mismatch will cause runtime failures
3. ‚ö†Ô∏è **Cold start latency**: Edge Functions sleep after 5 minutes idle - first request after idle will take 500-2000ms (unacceptable for trading)
4. ‚ö†Ô∏è **Missing database schema**: No `signal_analyses` table - where do results get stored? Signals table? New table? Unclear.
5. ‚ö†Ô∏è **Prompt template access**: `promptManager.getActivePromptContent()` queries Supabase - Edge Function needs same prompts but may not have access to same API

#### Hidden Complexity

1. **Gemini API integration without Firebase AI Logic**
   - **Challenge**: Browser uses Firebase AI Logic (`getGenerativeModel(ai, { model })`) which abstracts API key management, retry logic, streaming. Direct Gemini API requires manual implementation of all this.
   - **Mitigation**:
     - Use Gemini REST API directly: `POST https://generativelanguage.googleapis.com/v1/models/{model}:generateContent`
     - API key from Supabase secrets: `Deno.env.get('GEMINI_API_KEY')`
     - Simplified (no streaming for V1): Wait for full response, parse JSON
     - Retry logic: 3 attempts with exponential backoff (copied from ConcurrentAnalyzer pattern)
   - **Complexity adds**: ~200 lines of API client code vs. 10 lines with Firebase AI Logic
   - **Time estimate**: 3-4 hours for API client + error handling

2. **Schema mismatch between Fly machine signal format and Edge Function expectations**
   - **Challenge**: ConcurrentAnalyzer passes `{ signalId, traderId, symbol }` but browserAnalysisEngine expects `{ symbol, price, volume, klines, calculatedIndicators, strategy }` - **massive gap**.
   - **Current flow**:
     ```
     Fly: Detects signal ‚Üí Queues {signalId, traderId, symbol}
     ??? ‚Üí Edge Function needs full market data (klines, price, indicators)
     ```
   - **Solution (DECIDED)**:
     - ConcurrentAnalyzer fetches market data from database + calculates indicators using existing screenerHelpers before calling Edge Function
     - Edge Function receives complete analysis payload: `{ symbol, price, klines, calculatedIndicators, strategy }`
     - **Benefit**: No need to port screenerHelpers to Deno, Edge Function is pure AI logic (simpler, faster)
   - **Time estimate**: 2-3 hours to implement data fetching + indicator calculation logic in ConcurrentAnalyzer

3. **Database schema for storing analysis results**
   - **Challenge**: No dedicated `signal_analyses` table exists. Current options:
     - **signals table**: Has `status`, `matched_conditions`, `price` but no analysis fields
     - **monitoring_decisions table**: Has `decision`, `confidence`, `reasoning`, `trade_plan` but designed for workflow monitoring, not initial analysis
   - **Recommendation**: Create new `signal_analyses` table:
     ```sql
     CREATE TABLE signal_analyses (
       id UUID PRIMARY KEY,
       signal_id UUID REFERENCES signals(id),
       decision TEXT,  -- 'enter_trade', 'bad_setup', 'wait'
       confidence DECIMAL,
       reasoning TEXT,
       key_levels JSONB,  -- {entry, stopLoss, takeProfit[], support[], resistance[]}
       trade_plan JSONB,
       technical_indicators JSONB,
       raw_ai_response JSONB,  -- For debugging/retraining
       analysis_latency_ms INTEGER,
       gemini_tokens_used INTEGER,
       model_name TEXT,
       created_at TIMESTAMPTZ DEFAULT NOW()
     );
     ```
   - **Migration required**: Yes - new table, RLS policies, indexes
   - **Time estimate**: 1-2 hours for migration + testing

4. **Cold start mitigation strategy**
   - **Challenge**: Supabase Edge Functions hibernate after 5 minutes of inactivity. During volatile markets (Bitcoin flash crash), first signal triggers cold start = 500-2000ms latency penalty = missed entry.
   - **Current cold start behavior**:
     - Request 1 (cold): 500-2000ms setup + 1-3s Gemini = 1.5-5s total ‚ùå
     - Request 2+ (warm): 50-100ms overhead + 1-3s Gemini = 1-3.1s total ‚úÖ
   - **Mitigation strategies**:
     1. **Health check pings** (Recommended): Fly machine pings Edge Function every 4 minutes
        - Pro: Simple, reliable
        - Con: Wastes ~720 Edge Function invocations/day per user (~$0.01/month cost)
     2. **Provisioned concurrency**: Some serverless platforms support always-warm instances
        - Pro: Zero cold starts
        - Con: Supabase Edge Functions don't support this yet (Deno Deploy feature request)
     3. **Accept cold starts**: First signal slow, rest fast
        - Pro: No additional cost/complexity
        - Con: Poor UX for first signal after idle period
   - **Decision**: Implement health check pings (Option 1) - cost is negligible, UX is critical
   - **Time estimate**: 1 hour to add ping logic to Fly machine

#### Performance Concerns

**Bottlenecks identified:**

1. **Edge Function cold starts (500-2000ms)**
   - **Impact**: First analysis after 5+ minutes idle will violate <5s SLA
   - **Mitigation**: Health check pings every 4 minutes (keeps function warm)
   - **Monitoring**: Track cold start ratio (should be <1% with pings)

2. **Gemini API quota exhaustion during volatility**
   - **Impact**: 60 req/min limit shared across all Elite users. 10 users √ó 10 signals/min = 100 req/min = **quota exceeded**
   - **Mitigation**: ConcurrentAnalyzer already has rate limiter (60 req/min) - queue absorbs bursts
   - **Risk**: If queue backs up >5 minutes, analysis becomes stale
   - **Solution**: Priority queue (high-confidence signals jump line), fallback to browser analysis if queue >100 deep

3. **Indicator calculation overhead**
   - **Impact**: Calculating 40+ indicators for 100 klines adds ~50-200ms latency
   - **Solution**: Fly machine calculates indicators using existing screenerHelpers before calling Edge Function
   - **Benefit**: Edge Function receives pre-calculated indicators, no additional latency
   - **Monitoring**: Track indicator calculation time separately from Gemini API time

**During peak usage (Bitcoin flash crash scenario):**
- **Expected load**: 10 Elite users √ó 100 symbols √ó 10% trigger rate = 100 signals in 10 minutes = 10 signals/minute sustained
- **Current capacity**:
  - ConcurrentAnalyzer: 4 concurrent, 60/min = handles 10/min easily ‚úÖ
  - Gemini API: 60 req/min hard limit = can handle 10/min ‚úÖ
  - Edge Function: Auto-scales, no limit ‚úÖ
- **Scaling needed**:
  - If 50 Elite users: 50 signals/min = close to Gemini limit (60/min)
  - Need per-user rate limiting (4 concurrent per user) to prevent one user starving others
  - ConcurrentAnalyzer already implements this ‚úÖ

### Architecture Recommendations

#### Proposed Approach

**Layered architecture with clear separation of concerns:**

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Fly Machine (Node.js)                                       ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ
‚îÇ  ‚îÇ Binance WS  ‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ Filter Exec  ‚îÇ‚îÄ‚îÄ‚îÄ‚Üí‚îÇ Signal Created  ‚îÇ‚îÇ
‚îÇ  ‚îÇ Kline Stream‚îÇ    ‚îÇ              ‚îÇ    ‚îÇ                 ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                                                    ‚îÇ         ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê‚îÇ         ‚îÇ
‚îÇ  ‚îÇ ConcurrentAnalyzer                           ‚îÇ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - Fetches full signal data from DB           ‚îÇ‚îÇ         ‚îÇ
‚îÇ  ‚îÇ - Calculates indicators via screenerHelpers  ‚îÇ‚îÇ‚óÑ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
‚îÇ  ‚îÇ - Queues for Edge Function call              ‚îÇ‚îÇ
‚îÇ  ‚îÇ - Priority management, rate limiting         ‚îÇ‚îÇ
‚îÇ  ‚îÇ - Retry logic (3 attempts, exponential)      ‚îÇ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò‚îÇ
‚îÇ                     ‚îÇ                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ HTTP POST
                      ‚îÇ {symbol, price, klines,
                      ‚îÇ  indicators, strategy}
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Supabase Edge Function (Deno)                              ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ ai-analysis/index.ts                                  ‚îÇ ‚îÇ
‚îÇ  ‚îÇ                                                        ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  1. Validate request schema                           ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  2. Construct Gemini prompt (same as browser)         ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  3. POST to Gemini API                                ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  4. Parse & validate JSON response                    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  5. Calculate key levels (ATR-based stops)            ‚îÇ ‚îÇ
‚îÇ  ‚îÇ  6. Return structured analysis                        ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  Dependencies:                                               ‚îÇ
‚îÇ  - Gemini API client (direct REST, no Firebase)             ‚îÇ
‚îÇ  - Supabase client (for prompt fetching)                    ‚îÇ
‚îÇ  - Minimal helper functions for key level calculation       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                      ‚îÇ Response:
                      ‚îÇ {decision, confidence, reasoning,
                      ‚îÇ  keyLevels, tradePlan}
                      ‚ñº
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Fly Machine (continues)                                     ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ ConcurrentAnalyzer.handleTaskSuccess()               ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Emits 'analysis_complete' event                    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                            ‚îÇ                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ StateSynchronizer.queueAnalysis()                    ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Batches analysis results                           ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ - Writes to signal_analyses table (10s intervals)    ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key architectural decisions:**

1. **Fly machine owns data fetching**: Cleaner separation, Edge Function is pure AI logic
2. **Direct Gemini API (no Firebase)**: Simpler, faster, better error messages in serverless
3. **Indicators calculated on Fly**: Avoid duplicate calculation, reduce Edge Function latency
4. **New signal_analyses table**: Proper schema for storing results, keep signals table clean
5. **Health check warming**: Fly machine pings Edge Function every 4 minutes (prevents cold starts)

#### Data Flow

1. **Signal Detection** (Fly Machine)
   - WebSocket receives kline update
   - Filter executes, finds match
   - Signal created in database
   - ‚Üí Triggers analysis queue

2. **Pre-Analysis Data Prep** (Fly Machine - ConcurrentAnalyzer)
   - Fetch full signal record from database (trader_id, symbol, price)
   - Load trader config (strategy description, filter indicators)
   - Fetch historical klines (last 100 bars for AI context)
   - Calculate technical indicators using screenerHelpers
   - Construct analysis request payload

3. **AI Analysis** (Edge Function)
   - Validate request schema (TypeScript interfaces)
   - Fetch prompt template from database
   - Construct Gemini prompt with market data + strategy
   - Call Gemini API (with retry logic)
   - Parse JSON response, validate structure
   - Calculate key levels (support/resistance, ATR-based stops)
   - Return structured analysis result

4. **Post-Analysis Storage** (Fly Machine - StateSynchronizer)
   - Receive analysis result from Edge Function
   - Emit 'analysis_complete' event
   - Queue for batch write to database
   - Write to signal_analyses table (every 10 seconds)
   - Update signal status if needed

5. **UI Update** (Browser - Real-time)
   - Supabase Realtime listens to signal_analyses inserts
   - Browser receives new analysis
   - Updates UI with decision, confidence, trade plan
   - Shows notification if enabled

#### Key Components

**New:**
- `supabase/functions/ai-analysis/index.ts`: Main Edge Function handler (~300 lines)
- `supabase/functions/ai-analysis/geminiClient.ts`: Direct Gemini API integration (~200 lines)
- `supabase/functions/ai-analysis/keyLevelCalculator.ts`: ATR-based stops, support/resistance (~100 lines)
- `supabase/functions/ai-analysis/types.ts`: Shared type definitions (~100 lines)
- `supabase/migrations/014_create_signal_analyses_table.sql`: New database schema

**Modified:**
- `server/fly-machine/services/ConcurrentAnalyzer.ts:148-160`: Implement data fetching, indicator calculation, HTTP call to Edge Function
- `server/fly-machine/services/StateSynchronizer.ts`: Add `queueAnalysis()` method for batch writes
- `server/fly-machine/Orchestrator.ts`: Add health check ping logic (keep Edge Function warm)
- `server/fly-machine/types.ts`: Add shared type definitions for Edge Function payloads

**Deprecated:**
- None (this is additive feature, no removals)

### Implementation Complexity

#### Effort Breakdown
- **Frontend**: S (1-2 hours)
  - Already displays analysis results from browser
  - Just needs to handle cloud-sourced analyses (same data structure)
  - Minor: Add "Analyzed in cloud" badge to distinguish source

- **Backend - Edge Function**: M (6-8 hours) ‚¨áÔ∏è **50% REDUCTION** (no screenerHelpers port)
  - Gemini API client implementation: 3-4 hours
  - Prompt template integration: 1-2 hours
  - Key level calculation functions: 1 hour
  - Error handling, retries, validation: 1-2 hours
  - Testing with real signals: 1 hour

- **Backend - Fly Machine**: M (8-10 hours)
  - ConcurrentAnalyzer data fetching logic: 2-3 hours
  - Indicator calculation integration: 2-3 hours
  - HTTP client implementation: 2-3 hours
  - Health check ping implementation: 1 hour
  - Integration testing: 1-2 hours

- **Infrastructure**: M (4-6 hours)
  - Database migration (signal_analyses table): 1 hour
  - Supabase secrets setup (GEMINI_API_KEY): 0.5 hours
  - Edge Function deployment + testing: 1-2 hours
  - Monitoring/logging setup: 1-2 hours
  - Load testing (burst scenarios): 1-2 hours

- **Testing**: L (8-10 hours)
  - Unit tests for Edge Function: 3-4 hours
  - Integration tests (Fly ‚Üí Edge Function ‚Üí DB): 2-3 hours
  - Performance tests (latency, throughput): 2-3 hours
  - Chaos tests (Gemini errors, network failures): 1-2 hours

**Total Estimate**: 24-32 hours (3-4 days for experienced developer)
**Reduction**: 6-8 hours saved by NOT porting screenerHelpers to Deno

#### Risk Assessment
| Risk | Likelihood | Impact | Mitigation |
|------|------------|--------|------------|
| **~~screenerHelpers incompatibility with Deno~~** | ~~Medium~~ | ~~Critical~~ | ‚úÖ **ELIMINATED** - Indicators calculated on Fly machine, not ported to Deno |
| **Gemini API quota exhaustion (flash crash)** | High | High | Priority queue in ConcurrentAnalyzer; per-user rate limits (4 concurrent); fallback to browser analysis if queue >100; alert at 80% quota |
| **Edge Function cold starts >2s** | Medium | High | Health check pings every 4 minutes from Fly machine; monitor cold start ratio (target <1%); fallback to browser if timeout |
| **Schema mismatch (Fly vs Edge Function)** | Low | Critical | Strict TypeScript interfaces shared between projects; integration tests with real database; schema validation on both ends |
| **Analysis quality degradation** | Medium | High | Use identical prompts as browser; side-by-side testing with 100 historical signals; gradual rollout with quality monitoring |
| **Database write failures (signal_analyses)** | Low | Medium | StateSynchronizer retry logic; local queue backup; alert on consecutive failures |
| **Gemini returns malformed JSON** | Medium | Medium | JSON schema validation; 3-tier fallback (retry ‚Üí safe default ‚Üí log); store raw responses for debugging |
| **Latency >5s P95** | Medium | High | Pre-calculate indicators on Fly; optimize prompt size; parallel data fetching; monitor P95 latency (alert >5s) |

### Security Considerations

#### Authentication/Authorization
- **Edge Function authentication**:
  - Uses Supabase service role key (passed in request headers)
  - Validates request comes from known Fly machine IP (optional: IP whitelist)
  - **Risk**: Compromised service key = unauthorized Gemini API usage
  - **Mitigation**: Rotate keys monthly; monitor unusual request patterns; rate limit per source IP

- **Database access**:
  - Edge Function uses service role to bypass RLS (needs to write signal_analyses for any user)
  - Fly machine already authenticated via SUPABASE_SERVICE_KEY
  - **Risk**: Edge Function could theoretically access all user data
  - **Mitigation**: Principle of least privilege - Edge Function only queries prompts table and writes to signal_analyses

#### Data Protection
- **Sensitive data in requests**:
  - Trading strategy descriptions (proprietary user IP)
  - Historical kline data (public but could reveal trading intent)
  - Indicator values (derived, not sensitive)
- **Mitigation**:
  - All requests over HTTPS (Supabase Edge Functions enforce TLS)
  - No PII in analysis requests (just symbol, price, indicators)
  - raw_ai_response field encrypted at rest (Supabase default)

- **Gemini API key protection**:
  - Stored in Supabase secrets (encrypted, access-controlled)
  - Never logged or returned in responses
  - **Risk**: Key compromise = unlimited Gemini API usage on our billing
  - **Mitigation**: Set quota alerts in Google Cloud console; rotate monthly; monitor usage daily

#### API Security
- **Rate limiting**:
  - ConcurrentAnalyzer: 60 req/min globally, 4 concurrent per user
  - Edge Function: Inherits Supabase's default rate limits (100 req/min per IP)
  - Gemini API: 60 req/min quota (enforced by Google)
  - **Risk**: One rogue Fly machine could exhaust Gemini quota for all users
  - **Mitigation**: Per-user rate limiting in ConcurrentAnalyzer; circuit breaker after 10 consecutive failures; alert on >50 req/min sustained

- **Input validation**:
  - Request schema validation using TypeScript interfaces
  - Kline data sanitization (check for NaN, Infinity, malformed arrays)
  - Symbol validation (must match /^[A-Z]+USDT$/ pattern)
  - Strategy length limit (max 10,000 chars to prevent prompt injection)
  - **Risk**: Malicious input could inject prompts, cause Gemini errors, or DOS attack
  - **Mitigation**: Strict schema validation; prompt template escaping; request size limits (max 100KB)

### Testing Strategy

#### Unit Tests
**Edge Function (ai-analysis/index.ts):**
- ‚úÖ Validate request schema (missing fields, wrong types)
- ‚úÖ Gemini API client (success, 429 errors, malformed JSON, timeout)
- ‚úÖ Key level calculation (ATR-based stops, support/resistance)
- ‚úÖ Response parsing (valid JSON, missing fields, unexpected values)
- ‚úÖ Error handling (retry logic, fallback defaults, error logging)

**ConcurrentAnalyzer modifications:**
- ‚úÖ HTTP client error handling (network failures, 500 errors, timeouts)
- ‚úÖ Data fetching logic (missing signals, invalid trader configs)
- ‚úÖ Indicator calculation (verify outputs match existing screenerHelpers)
- ‚úÖ Payload construction (schema validation before sending)
- ‚úÖ Queue management (priority sorting, retry exponential backoff)

#### Integration Tests
**Critical paths:**
1. **Full analysis flow** (Fly ‚Üí Edge Function ‚Üí Database):
   - Create test signal in database
   - Trigger ConcurrentAnalyzer.analyzeSignal()
   - Verify Edge Function called with correct payload
   - Check signal_analyses table has result
   - Validate analysis structure matches browser output

2. **Error recovery**:
   - Mock Gemini API 500 error ‚Üí verify retry logic
   - Mock Edge Function timeout ‚Üí verify fallback to browser
   - Mock database write failure ‚Üí verify retry queue

3. **Rate limiting**:
   - Queue 100 signals rapidly ‚Üí verify only 4 concurrent, 60/min respected
   - Simulate 2 users ‚Üí verify per-user isolation (user A's burst doesn't block user B)

#### Performance Tests
**Load scenarios:**
1. **Baseline** (single signal):
   - Target: <3s P50, <5s P95 (match browser)
   - Measure: Edge Function latency, Gemini API time, total round-trip

2. **Burst** (10 signals in 10 seconds):
   - Target: All complete within 30s
   - Measure: Queue depth, concurrent tasks, rate limit hits

3. **Sustained** (100 signals over 10 minutes):
   - Target: Zero queue backlog growth
   - Measure: Queue depth over time, Gemini quota usage

4. **Flash crash** (50 signals in 60 seconds):
   - Target: High-priority signals analyzed within 10s
   - Measure: Queue depth, priority sorting effectiveness, stale analysis count

#### Chaos Engineering
**Failure scenarios:**
1. **Gemini API down** (simulated 503 errors for 5 minutes):
   - Expected: Queue backs up, but no crashes
   - Verify: Retry logic works, fallback to browser triggers, user notifications

2. **Edge Function cold start** (first request after 10 minutes):
   - Expected: 500-2000ms penalty on first request
   - Verify: Health check pings prevent this (cold start ratio <1%)

3. **Database connection loss** (Supabase network issue):
   - Expected: Writes fail but queued locally
   - Verify: StateSynchronizer retry logic, no data loss

4. **Malformed Gemini responses** (inject garbage JSON):
   - Expected: Parsing fails, safe default returned
   - Verify: No crashes, error logged with correlation ID

### Technical Recommendations

#### Must Have (Blocking for V1)
1. **Direct Gemini API integration** (no Firebase AI Logic) - avoid Deno compatibility issues
2. **Indicator calculation on Fly** - reuse existing screenerHelpers, pass calculated values to Edge Function
3. **Strict TypeScript interfaces** - prevent schema mismatch between Fly and Edge Function
4. **signal_analyses database table** - proper storage for results
5. **Health check warming** - prevent cold start latency SLA violations
6. **Comprehensive error handling** - 3-tier fallback, no crashes on Gemini errors
7. **Rate limiting coordination** - ConcurrentAnalyzer manages quota, Edge Function is stateless
8. **Integration tests** - full Fly ‚Üí Edge Function ‚Üí Database round-trip validated

#### Should Have (High Value)
1. **Priority queue implementation** - high-confidence signals jump the line during bursts
2. **Per-user rate limiting** - prevent one user starving others during flash crash
3. **Observability** - correlation IDs, latency tracking, Gemini token usage, error rates
4. **Analysis result caching** - 5-minute TTL for same symbol+strategy (30% cost savings)
5. **Fallback to browser analysis** - graceful degradation if Edge Function down
6. **Raw AI response storage** - invaluable for debugging, prompt optimization, model retraining
7. **Monitoring alerts** - >10% error rate, >5s P95 latency, >80% Gemini quota

#### Nice to Have (Future V2)
1. **Streaming response support** - SSE from Edge Function for progressive UI updates
2. **Analysis result history** - compare AI decisions over time for same setup
3. **A/B testing framework** - test prompt variations, model upgrades without breaking production
4. **Multi-region Edge Function deployment** - lower latency for Asian/European users
5. **Automated prompt optimization** - use historical analysis quality to tune prompts
6. **Cost attribution per user** - track Gemini token usage for billing transparency

### Implementation Guidelines

#### Code Organization
```
supabase/functions/ai-analysis/
‚îú‚îÄ‚îÄ index.ts                  # Main Edge Function handler (CORS, routing) ~300 lines
‚îú‚îÄ‚îÄ geminiClient.ts           # Direct Gemini API integration ~200 lines
‚îú‚îÄ‚îÄ types.ts                  # Shared TypeScript interfaces ~100 lines
‚îú‚îÄ‚îÄ promptBuilder.ts          # Constructs Gemini prompts ~150 lines
‚îú‚îÄ‚îÄ analysisParser.ts         # Validates & parses Gemini JSON responses ~100 lines
‚îú‚îÄ‚îÄ keyLevelCalculator.ts     # ATR-based stops, support/resistance ~100 lines
‚îú‚îÄ‚îÄ tests/
‚îÇ   ‚îú‚îÄ‚îÄ geminiClient.test.ts
‚îÇ   ‚îú‚îÄ‚îÄ keyLevels.test.ts
‚îÇ   ‚îú‚îÄ‚îÄ integration.test.ts
‚îÇ   ‚îî‚îÄ‚îÄ fixtures/
‚îÇ       ‚îî‚îÄ‚îÄ sampleRequest.json  # Sample analysis request payload
‚îî‚îÄ‚îÄ deno.json                  # Import map, permissions

server/fly-machine/
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îî‚îÄ‚îÄ ConcurrentAnalyzer.ts  # MODIFIED: Add indicator calculation + HTTP client
‚îî‚îÄ‚îÄ types.ts                   # MODIFIED: Add shared Edge Function payload types
```

#### Key Decisions

**State management:**
- Edge Function is **stateless** - no in-memory caching, no global variables
- All state in request/response or database
- Rationale: Serverless functions can scale to zero and back - any in-memory state is lost

**Data fetching & indicator calculation:**
- Fly machine (ConcurrentAnalyzer) fetches signal data, klines, and calculates ALL indicators using existing screenerHelpers **before** calling Edge Function
- Edge Function receives complete analysis payload: `{ symbol, price, klines, calculatedIndicators, strategy }`
- Rationale:
  - Cleaner separation of concerns (Edge Function = pure AI logic)
  - No need to port screenerHelpers to Deno (saves 6-8 hours)
  - Reuses existing, tested indicator code
  - Reduces Edge Function complexity and latency

**Caching:**
- V1: No caching (keep it simple)
- V2: In-memory cache in Edge Function with 5-minute TTL (if Deno supports)
- Rationale: Same symbol+strategy within 5 minutes likely has identical analysis

**Error handling:**
- 3-tier fallback:
  1. Retry once with same prompt (transient Gemini errors)
  2. Return safe default `{ decision: 'bad_setup', confidence: 0, reasoning: 'Analysis failed' }`
  3. Log error with full context (correlation ID, request payload, Gemini response)
- Rationale: Never crash, always return something, but log for investigation

### Questions for PM/Design

1. **[Data fetching responsibility]**: Should Fly machine or Edge Function fetch signal data from database?
   - **Engineering recommendation**: Fly machine (ConcurrentAnalyzer) fetches everything, Edge Function is pure AI
   - **Trade-off**: More complex Fly code, but cleaner Edge Function

2. **[Analysis result storage]**: New signal_analyses table or extend signals table?
   - **Engineering recommendation**: New table - cleaner schema, better performance (signals table is high-write)
   - **Trade-off**: Requires migration, but future-proof for multiple analyses per signal

3. **[Cold start tolerance]**: Is 500-2000ms latency acceptable for first signal after idle period?
   - **Engineering recommendation**: No - implement health check pings (keeps function warm)
   - **Trade-off**: Costs ~$0.01/month/user in wasted Edge Function invocations

4. **[Rate limit handling]**: When Gemini quota exhausted, fall back to browser or queue until quota resets?
   - **Engineering recommendation**: Both - immediate fallback for current signal, queue others
   - **Trade-off**: Complexity, but best UX

5. **[Prompt template source]**: Should Edge Function fetch prompts from database or have them hardcoded?
   - **Engineering recommendation**: Fetch from database (same source as browser) for consistency
   - **Trade-off**: Extra database query, but ensures prompts stay in sync

### Pre-Implementation Checklist

- [x] Performance requirements achievable (<5s P95 with direct Gemini API + warm function)
- [x] Security model defined (service role auth, Supabase secrets for API key, HTTPS only)
- [ ] Error handling strategy clear (Need PM decision on fallback behavior)
- [x] Monitoring plan in place (correlation IDs, latency tracking, error rates, Gemini quota)
- [x] Rollback strategy defined (disable Edge Function call in ConcurrentAnalyzer, falls back to browser)
- [x] Dependencies available (Deno, Supabase Edge Functions, Gemini API access)
- [x] No blocking technical debt (screenerHelpers port is doable, Firebase incompatibility addressed)

### Recommended Next Steps

**Verdict: ‚ö†Ô∏è Challenging - Address specific concerns before full implementation**

**Immediate Actions (Before Starting Implementation):**

1. **Resolve PM questions** (storage schema, rate limit behavior) - 1 day
   - ‚úÖ Data fetching: RESOLVED - Fly machine calculates indicators

2. **Proof of Concept**: Direct Gemini API call from Deno
   - Write minimal Edge Function that calls Gemini
   - Test with structured analysis prompt
   - Measure latency (should be <3s)
   - **Time**: 2 hours
   - **Go/No-Go**: If errors or >5s latency, investigate Deno HTTP client issues

3. **Database schema decision**: Create signal_analyses table migration
   - Draft migration script
   - Review with PM (is schema structure correct?)
   - **Time**: 1 hour

**Then proceed to:**
1. `/architect issues/2025-10-05-ai-analysis-edge-function.md` - detailed component design
2. `/plan issues/2025-10-05-ai-analysis-edge-function.md` - step-by-step implementation plan

**Risk Mitigation:**
- ‚úÖ **Major risk eliminated**: No screenerHelpers porting needed (Fly machine calculates indicators)
- Gemini API POC validates core technical assumption (Deno can call Gemini)
- If POC fails, we know immediately (before spending 24-32 hours on full implementation)
- Having PM decisions upfront prevents mid-implementation pivots

**Summary of Architectural Change:**
- **Before**: Edge Function calculates indicators (1,420 lines to port, 4-6 hours effort, Deno compatibility risk)
- **After**: Fly machine calculates indicators, Edge Function receives pre-calculated values (0 lines to port, 0 hours effort, zero risk)
- **Impact**: 50% reduction in Edge Function complexity, 20-25% reduction in total effort, eliminates highest-risk item

---
*[End of engineering review. Next: /architect issues/2025-10-05-ai-analysis-edge-function.md]*
